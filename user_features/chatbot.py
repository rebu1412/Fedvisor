import streamlit as st
import sqlite3
import google.generativeai as genai
from create_user.database import track_usage
st.set_page_config(layout="wide")

# Cáº¥u hÃ¬nh API cá»§a Gemini
genai.configure(api_key=st.secrets["API_KEY"])

# Danh sÃ¡ch chá»§ Ä‘á»
TOPIC_OPTIONS = ["Táº¥t cáº£", "Há»c phÃ­", "Tuyá»ƒn sinh", "Há»c bá»•ng", "ChÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o", "KhÃ¡c"]

def get_data_from_db(topic_filter):
    """Láº¥y dá»¯ liá»‡u tá»« database theo chá»§ Ä‘á» Ä‘Ã£ chá»n."""
    db_path = "data/data.db"

    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT title, content FROM admin_info WHERE topic = ?", (topic_filter,))
        data = cursor.fetchall()

    if not data:
        return None

    formatted_data = "\n\n".join([f"Title: {row[0]}\nContent: {row[1]}" for row in data])
    return formatted_data

def chatbot():
    """Giao diá»‡n chatbot vá»›i tracking"""
    col1, col2 = st.columns([3, 1])

    with col1:
        st.subheader("ğŸ’¬ Há»i Ä‘Ã¡p cÃ¹ng Chatbot")
        topic_filter = st.selectbox("ğŸ¯ Chá»n chá»§ Ä‘á»", TOPIC_OPTIONS, index=0)
        context_text = None if topic_filter == "Táº¥t cáº£" else get_data_from_db(topic_filter)
        user_query = st.text_input("âœï¸ Nháº­p cÃ¢u há»i cá»§a báº¡n:")

        if user_query:
            track_usage("chatbot_usage")  # Äáº¿m sá»‘ láº§n sá»­ dá»¥ng chatbot

            # XÃ¢y dá»±ng prompt
            if topic_filter == "Táº¥t cáº£":
                prompt = f"Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»— trá»£ sinh viÃªn. Chá»§ Ä‘á»: {topic_filter}. CÃ¢u há»i: {user_query}"
            elif context_text:
                prompt = f"Báº¡n lÃ  má»™t trá»£ lÃ½ AI. Chá»§ Ä‘á»: {topic_filter}. Dá»¯ liá»‡u trÆ°á»ng: {context_text}. CÃ¢u há»i: {user_query}"
            else:
                prompt = f"Báº¡n lÃ  má»™t trá»£ lÃ½ AI. Chá»§ Ä‘á»: {topic_filter}. Hiá»‡n khÃ´ng cÃ³ dá»¯ liá»‡u tá»« trÆ°á»ng. CÃ¢u há»i: {user_query}"

            # Gá»­i yÃªu cáº§u Ä‘áº¿n AI
            try:
                llm = genai.GenerativeModel('gemini-1.5-flash')
                response = llm.generate_content(prompt)
                st.write("### ğŸ“¢ Tráº£ lá»i tá»« Chatbot:")
                st.success(response.text)
            except Exception as e:
                st.error(f"Lá»—i káº¿t ná»‘i API: {e}")

    with col2:
        st.subheader("ğŸ“Œ Nhá»¯ng chá»§ Ä‘á» báº¡n cÃ³ thá»ƒ há»i")
        for topic in TOPIC_OPTIONS:
            st.info(f"âœ… **{topic}**")

